{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inverse_burger.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ZpMIxMItv_Wduu8jEvSj8TDict9bpMpM","authorship_tag":"ABX9TyOkd4qwCrzmsCPBoEgWocKk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dbUxPK9Ov8Dj"},"source":["### Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esPyL_zpyi-m","executionInfo":{"status":"ok","timestamp":1623206860064,"user_tz":420,"elapsed":110353,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}},"outputId":"65c593b9-27de-4ea0-9fbc-3a0d515baf0c"},"source":["!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.7.1+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.4MB)\n","\u001b[K     |████████████████████████████████| 735.4MB 25kB/s \n","\u001b[?25hCollecting torchvision==0.8.2+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 39.3MB/s \n","\u001b[?25hCollecting torchaudio==0.7.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/16/ecdb9eb09ec6b8133d6c9536ea9e49cd13c9b5873c8488b8b765a39028da/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (7.1.2)\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1+cu101 which is incompatible.\u001b[0m\n","Installing collected packages: torch, torchvision, torchaudio\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","  Found existing installation: torchvision 0.9.1+cu101\n","    Uninstalling torchvision-0.9.1+cu101:\n","      Successfully uninstalled torchvision-0.9.1+cu101\n","Successfully installed torch-1.7.1+cu101 torchaudio-0.7.2 torchvision-0.8.2+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQYW9RPL55YU","executionInfo":{"status":"ok","timestamp":1623294668867,"user_tz":420,"elapsed":523,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}},"outputId":"3ab38620-2502-4700-fcf8-0f23a6ab3579"},"source":["cd /content/drive/MyDrive/fourier_neural_operator/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/fourier_neural_operator\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdkpwJpf5s2S","executionInfo":{"status":"ok","timestamp":1623294749639,"user_tz":420,"elapsed":11,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}},"outputId":"434d9be2-5147-40a4-a537-630e9b2856b6"},"source":["!cp ../fourier_neural_operator/inverse_ns.ipynb ."],"execution_count":5,"outputs":[{"output_type":"stream","text":["cp: cannot stat '../fourier_neural_operator/inverse_ns.ipynb': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xjjFYgZV9lyj","executionInfo":{"status":"ok","timestamp":1623206862152,"user_tz":420,"elapsed":2115,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torchvision.transforms import Normalize\n","import matplotlib.pyplot as plt\n","\n","import operator\n","from functools import reduce\n","from functools import partial\n","from timeit import default_timer\n","from utilities3 import *\n","import random\n","import time\n","\n","torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-jPOIGZ6wAzr"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"8IiD8unq9p72","executionInfo":{"status":"ok","timestamp":1623206862741,"user_tz":420,"elapsed":595,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["#Complex multiplication\n","def compl_mul1d(a, b):\n","    # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n","    op = partial(torch.einsum, \"bix,iox->box\")\n","    return torch.stack([\n","        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n","        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n","    ], dim=-1)\n","\n","################################################################\n","#  1d fourier layer\n","################################################################\n","class SpectralConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, modes1):\n","        super(SpectralConv1d, self).__init__()\n","\n","        \"\"\"\n","        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n","        \"\"\"\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n","\n","        self.scale = (1 / (in_channels*out_channels))\n","        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, 2))\n","\n","    def forward(self, x):\n","        batchsize = x.shape[0]\n","        #Compute Fourier coeffcients up to factor of e^(- something constant)\n","        x_ft = torch.rfft(x, 1, normalized=True, onesided=True)\n","\n","        # Multiply relevant Fourier modes\n","        out_ft = torch.zeros(batchsize, self.in_channels, x.size(-1)//2 + 1, 2, device=x.device)\n","        out_ft[:, :, :self.modes1] = compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n","\n","        #Return to physical space\n","        x = torch.irfft(out_ft, 1, normalized=True, onesided=True, signal_sizes=(x.size(-1), ))\n","        return x\n","\n","class SimpleBlock1d(nn.Module):\n","    def __init__(self, modes, width):\n","        super(SimpleBlock1d, self).__init__()\n","\n","        \"\"\"\n","        The overall network. It contains 4 layers of the Fourier layer.\n","        1. Lift the input to the desire channel dimension by self.fc0 .\n","        2. 4 layers of the integral operators u' = (W + K)(u).\n","            W defined by self.w; K defined by self.conv .\n","        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n","        \n","        input: the solution of the initial condition and location (a(x), x)\n","        input shape: (batchsize, x=s, c=2)\n","        output: the solution of a later timestep\n","        output shape: (batchsize, x=s, c=1)\n","        \"\"\"\n","\n","        self.modes1 = modes\n","        self.width = width\n","        self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n","\n","        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.w0 = nn.Conv1d(self.width, self.width, 1)\n","        self.w1 = nn.Conv1d(self.width, self.width, 1)\n","        self.w2 = nn.Conv1d(self.width, self.width, 1)\n","        self.w3 = nn.Conv1d(self.width, self.width, 1)\n","\n","        self.fc1 = nn.Linear(self.width, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","\n","        x = self.fc0(x)\n","        x = x.permute(0, 2, 1)\n","\n","        x1 = self.conv0(x)\n","        x2 = self.w0(x)\n","        x = x1 + x2\n","        x = F.relu(x)\n","\n","        x1 = self.conv1(x)\n","        x2 = self.w1(x)\n","        x = x1 + x2\n","        x = F.relu(x)\n","\n","        x1 = self.conv2(x)\n","        x2 = self.w2(x)\n","        x = x1 + x2\n","        x = F.relu(x)\n","\n","        x1 = self.conv3(x)\n","        x2 = self.w3(x)\n","        x = x1 + x2\n","\n","        x = x.permute(0, 2, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","class Net1d(nn.Module):\n","    def __init__(self, modes, width):\n","        super(Net1d, self).__init__()\n","\n","        \"\"\"\n","        A wrapper function\n","        \"\"\"\n","\n","        self.conv1 = SimpleBlock1d(modes, width)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        return x.squeeze()\n","\n","    def count_params(self):\n","        c = 0\n","        for p in self.parameters():\n","            c += reduce(operator.mul, list(p.size()))\n","\n","        return c"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4XZDtIRwLgi","executionInfo":{"status":"ok","timestamp":1623206874581,"user_tz":420,"elapsed":11841,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["################################################################\n","#  Load Data\n","################################################################\n","\n","dataloader = MatReader('data/burgers_data_R10.mat')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xV3KCmRhsKXZ"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"kprefXwfrrdD"},"source":["################################################################\n","#  Training configurations\n","################################################################\n","\n","ntrain = 1000\n","ntest = 100\n","\n","sub = 2**3 #subsampling rate\n","h = 2**13 // sub #total grid size divided by the subsampling rate\n","s = h\n","\n","batch_size = 20\n","learning_rate = 0.001\n","\n","epochs = 500\n","step_size = 100\n","gamma = 0.5\n","\n","modes = 16\n","width = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IdhwtwWrx_d","executionInfo":{"status":"ok","timestamp":1623132595552,"user_tz":420,"elapsed":2483,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}},"outputId":"04622200-1db1-4072-f378-5628417d0627"},"source":["################################################################\n","# Process training and testing dataset\n","################################################################\n","\n","x_data = dataloader.read_field('a')[:,::sub]\n","y_data = dataloader.read_field('u')[:,::sub]\n","\n","x_train = x_data[:ntrain,:]\n","y_train = y_data[:ntrain,:]\n","x_test = x_data[-ntest:,:]\n","y_test = y_data[-ntest:,:]\n","\n","# cat the locations information\n","grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n","grid = torch.tensor(grid, dtype=torch.float)\n","x_train = torch.cat([x_train.reshape(ntrain,s,1), grid.repeat(ntrain,1,1)], dim=2)\n","x_test = torch.cat([x_test.reshape(ntest,s,1), grid.repeat(ntest,1,1)], dim=2)\n","\n","train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n","\n","# model\n","model = Net1d(modes, width).cuda()\n","print(model.count_params())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["549569\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MiKO1Gm8wwzL"},"source":["################################################################\n","# training and evaluation\n","################################################################\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","myloss = LpLoss(size_average=False)\n","for ep in range(epochs):\n","    model.train()\n","    t1 = default_timer()\n","    train_mse = 0\n","    train_l2 = 0\n","    for x, y in train_loader:\n","        x, y = x.cuda(), y.cuda()\n","\n","        optimizer.zero_grad()\n","        out = model(x)\n","\n","        mse = F.mse_loss(out, y, reduction='mean')\n","        # mse.backward()\n","        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n","        l2.backward() # use the l2 relative loss\n","\n","        optimizer.step()\n","        train_mse += mse.item()\n","        train_l2 += l2.item()\n","\n","    scheduler.step()\n","    model.eval()\n","    test_l2 = 0.0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x, y = x.cuda(), y.cuda()\n","\n","            out = model(x)\n","            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n","\n","    train_mse /= len(train_loader)\n","    train_l2 /= ntrain\n","    test_l2 /= ntest\n","\n","    t2 = default_timer()\n","    print(ep, t2-t1, train_mse, train_l2, test_l2)\n","\n","if not os.path.exists(os.path.join(os.getcwd(), 'model')):\n","    os.makedirs(os.path.join(os.getcwd(), 'model'))\n","# torch.save(model, 'model/ns_fourier_burgers_8192')\n","pred = torch.zeros(y_test.shape)\n","index = 0\n","test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        test_l2 = 0\n","        x, y = x.cuda(), y.cuda()\n","\n","        out = model(x)\n","        pred[index] = out\n","\n","        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n","        print(index, test_l2)\n","        index = index + 1\n","\n","# scipy.io.savemat('pred/burger_test.mat', mdict={'pred': pred.cpu().numpy()})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJMkxQ47sVae"},"source":["### Inverse"]},{"cell_type":"code","metadata":{"id":"dzYqOMhG9saJ","executionInfo":{"status":"ok","timestamp":1623206874581,"user_tz":420,"elapsed":14,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["################################################################\n","#  inverse configurations\n","################################################################\n","ntrain = 1000\n","\n","sub = 2**3 #subsampling rate\n","h = 2**13 // sub #total grid size divided by the subsampling rate\n","s = h\n","\n","learning_rate = 0.1\n","coef = 0.0001\n","\n","epochs = 1500\n","step_size = 100\n","gamma = 0.5"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"be_EqIRy9u4E","executionInfo":{"status":"ok","timestamp":1623206874582,"user_tz":420,"elapsed":14,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["################################################################\n","# Process inverse dataset\n","################################################################\n","\n","x_data = dataloader.read_field('a')[:,::sub]\n","y_data = dataloader.read_field('u')[:,::sub]\n","\n","index = random.randint(0,ntrain)\n","x_groundtruth = x_data[index,:]\n","y = y_data[index,:]\n","\n","grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n","grid = torch.tensor(grid, dtype=torch.float)\n","x_groundtruth = torch.cat([x_groundtruth.reshape(1,s,1), grid.repeat(1,1,1)], dim=2)\n","y = y.reshape(1,1024)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2WxiZjkwgOY","executionInfo":{"status":"ok","timestamp":1623206878555,"user_tz":420,"elapsed":3986,"user":{"displayName":"Jin David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwyAyGrqhRB7LSRaY_vUM2DxNKemRhx5nV46n5EA=s64","userId":"09060006220293561308"}}},"source":["################################################################\n","# load model\n","################################################################\n","\n","PATH = 'model/ns_fourier_burgers_8192'\n","model = torch.load(PATH)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiQ4Umsr4wey"},"source":["################################################################\n","# Inverse\n","################################################################\n","\n","#randomly generate parameters\n","x = torch.rand(x_groundtruth.shape, requires_grad=True, device=\"cuda\")\n","# x = torch.norm(F.normalize(x_groundtruth, p=2, dim=1)).weight * torch.rand(x_groundtruth.shape, requires_grad=True).weight\n","# print(x)\n","# exit()\n","y, x_groundtruth = y.cuda(), x_groundtruth.cuda()\n","lr = 0.1\n","optimizer = torch.optim.SGD([x], lr=lr, momentum=0.9)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","myloss = nn.MSELoss()\n","\n","t0 = time.time()\n","\n","# x_first = x.clone()\n","\n","for i in range(epochs):\n","\n","    optimizer.zero_grad()\n","    output = model(x)\n","    loss = myloss(output.view(1, -1), y.view(1, -1))\n","    loss_groundtruth = myloss(x.view(1, -1), x_groundtruth.view(1, -1))\n","\n","    loss.backward(retain_graph=True)\n","    loss_groundtruth.backward()\n","    \n","    optimizer.step()\n","    scheduler.step()\n","\n","    print(i, loss.item(), loss_groundtruth.item())\n","    model.eval()\n","\n","\n","    # noise generation\n","    # noise = x.clone()\n","    # noise = coef * learning_rate * torch.norm(noise) * torch.randn(x.shape, requires_grad=False, device=\"cuda\")\n","    # x = x + noise\n","\n","# x_final = x.clone()\n","\n","t1 = time.time()\n","\n","print((t1-t0)/epochs)"],"execution_count":null,"outputs":[]}]}